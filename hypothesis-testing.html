<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Hypothesis Testing | Statistics</title>
  <meta name="description" content="5 Hypothesis Testing | Statistics" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Hypothesis Testing | Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="dyrehaugen/rsts" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Hypothesis Testing | Statistics" />
  
  
  

<meta name="author" content="Dyrehaugen Web Notebook" />


<meta name="date" content="2021-04-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inequality.html"/>
<link rel="next" href="power-law.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Statistics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#pandemic-risk-management"><i class="fa fa-check"></i><b>1.1</b> Pandemic Risk Management</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#quarantine-fatigue-thins-fat-tailed-impacts"><i class="fa fa-check"></i><b>1.2</b> Quarantine fatigue thins fat-tailed impacts</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#herd-immunity-impossible-with-new-mutants"><i class="fa fa-check"></i><b>1.3</b> Herd Immunity impossible with new Mutants</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#danish-mask-study"><i class="fa fa-check"></i><b>1.4</b> Danish Mask Study</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="fat-tails.html"><a href="fat-tails.html"><i class="fa fa-check"></i><b>2</b> Fat Tails</a>
<ul>
<li class="chapter" data-level="2.1" data-path="fat-tails.html"><a href="fat-tails.html#extremes"><i class="fa fa-check"></i><b>2.1</b> Extremes</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="fat-tails.html"><a href="fat-tails.html#catastrophe-principle"><i class="fa fa-check"></i><b>2.1.1</b> Catastrophe Principle</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="fat-tails.html"><a href="fat-tails.html#statistical-consequences-of-fat-tails"><i class="fa fa-check"></i><b>2.2</b> Statistical Consequences of Fat Tails</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="fat-tails.html"><a href="fat-tails.html#power-law-distributions"><i class="fa fa-check"></i><b>2.2.1</b> Power Law Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="fat-tails.html"><a href="fat-tails.html#lindy-effect"><i class="fa fa-check"></i><b>2.3</b> Lindy Effect</a></li>
<li class="chapter" data-level="2.4" data-path="fat-tails.html"><a href="fat-tails.html#superspreaders"><i class="fa fa-check"></i><b>2.4</b> Superspreaders</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="vaccine.html"><a href="vaccine.html"><i class="fa fa-check"></i><b>3</b> Vaccine</a></li>
<li class="chapter" data-level="4" data-path="inequality.html"><a href="inequality.html"><i class="fa fa-check"></i><b>4</b> Inequality</a></li>
<li class="chapter" data-level="5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#connecting-to-theory"><i class="fa fa-check"></i><b>5.1</b> Connecting to Theory</a></li>
<li class="chapter" data-level="5.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#glmm"><i class="fa fa-check"></i><b>5.2</b> GLMM</a></li>
<li class="chapter" data-level="5.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#logit"><i class="fa fa-check"></i><b>5.3</b> Logit</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#odds-ratio"><i class="fa fa-check"></i><b>5.3.1</b> Odd’s Ratio</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#probit"><i class="fa fa-check"></i><b>5.4</b> Probit</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="power-law.html"><a href="power-law.html"><i class="fa fa-check"></i><b>6</b> Power law</a>
<ul>
<li class="chapter" data-level="6.1" data-path="power-law.html"><a href="power-law.html#timescaling-rainfall"><i class="fa fa-check"></i><b>6.1</b> Timescaling Rainfall</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="syntetic-control.html"><a href="syntetic-control.html"><i class="fa fa-check"></i><b>7</b> Syntetic Control</a></li>
<li class="part"><span><b>I Appendices</b></span></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="about.html"><a href="about.html"><i class="fa fa-check"></i><b>A</b> About</a></li>
<li class="chapter" data-level="B" data-path="links.html"><a href="links.html"><i class="fa fa-check"></i><b>B</b> Links</a></li>
<li class="chapter" data-level="C" data-path="news.html"><a href="news.html"><i class="fa fa-check"></i><b>C</b> NEWS</a></li>
<li class="divider"></li>
<li><a href="https://github.com/dyrehaugen/rsts" target="blank">On Github</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Hypothesis Testing</h1>
<p>Some text here …</p>
<p><a href="https://cran.r-project.org/web/packages/distributions3/vignettes/intro-to-hypothesis-testing.html">Cran: Intro Hyp in R</a></p>
<p><a href="https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture07/lecture07-94842.html">Chouldechova: Hyp in R</a></p>
<div id="connecting-to-theory" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Connecting to Theory</h2>
<p><em>Memo</em></p>
<p>In order to bound the probability of Type 2 errors below a small value
we may have to accept a high probability of making a Type 1 error.</p>
<p><strong>Scheel</strong></p>
<p><em>Abstract</em></p>
<p>For almost half a century, Paul Meehl educated psychologists about how the mindless use of null-hypothesis significance
tests made research on theories in the social sciences basically uninterpretable. In response to the replication crisis,
reforms in psychology have focused on formalizing procedures for testing hypotheses. These reforms were necessary
and influential. However, as an unexpected consequence, psychological scientists have begun to realize that they
may not be ready to test hypotheses. Forcing researchers to prematurely test hypotheses before they have established
a sound “derivation chain” between test and theory is counterproductive. Instead, various nonconfirmatory research
activities should be used to obtain the inputs necessary to make hypothesis tests informative. Before testing hypotheses,
researchers should spend more time forming concepts, developing valid measures, establishing the causal relationships
between concepts and the functional form of those relationships, and identifying boundary conditions and auxiliary
assumptions. Providing these inputs should be recognized and incentivized as a crucial goal in itself. In this article, we
discuss how shifting the focus to nonconfirmatory research can tie together many loose ends of psychology’s reform
movement and help us to develop strong, testable theories, as Paul Meehl urged.</p>
<p><em>Memo Scheel</em></p>
<p>Excessive leniency
in study design, data collection, and analysis led psy-
chological scientists to be overconfident about many
hypotheses that turned out to be false. In response, psy-
chological science as a field tightened the screws on the
machinery of confirmatory testing: Predictions should be
more specific, designs more powerful, and statistical tests
more stringent, leaving less room for error and misrepre-
sentation. Confirmatory testing will be taught as a highly
formalized protocol with clear rules, and the student will
learn to strictly separate it from the “exploratory” part of
the research process. Has learned how
to operate the hypothesis-testing machinery but not
how to feed it with meaningful input.</p>
<p>When setting up a hypothesis test, the researcher has to specify
how their independent and dependent variables will
be operationalized, how many participants they will
collect, which exclusion criteria they will apply, which
statistical method they will use, how to decide whether
the hypothesis was corroborated or falsified, and so on.
But deciding between these myriad options often feels
like guesswork.</p>
<p>A lack of knowledge about the elements that link their test
back to the theory from which their hypothesis was
derived. By using arbitrary defaults and heuristics to
bridge these gaps, the researcher cannot be sure how
their test result informs the theory.</p>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/1745691620966795">Scheel(2020) Less Hypothesis Testing</a>
<a href="pdf/Scheel_2020_Less_Hypothesis_Testing.pdf">(pdf)</a></p>

</div>
<div id="glmm" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> GLMM</h2>
<p>The advent of generalized linear models has allowed us to build regression-type models of data when the distribution of the response variable is non-normal–for example, when your DV is binary. (If you would like to know a little more about GLiMs, I wrote a fairly extensive answer here, which may be useful although the context differs.) However, a GLiM, e.g. a logistic regression model, assumes that your data are independent. For instance, imagine a study that looks at whether a child has developed asthma. Each child contributes one data point to the study–they either have asthma or they don’t. Sometimes data are not independent, though. Consider another study that looks at whether a child has a cold at various points during the school year. In this case, each child contributes many data points. At one time a child might have a cold, later they might not, and still later they might have another cold. These data are not independent because they came from the same child. In order to appropriately analyze these data, we need to somehow take this non-independence into account. There are two ways: One way is to use the generalized estimating equations (which you don’t mention, so we’ll skip). The other way is to use a generalized linear mixed model. GLiMMs can account for the non-independence by adding random effects (as <span class="citation">(<a href="#ref-MichaelChernick" role="doc-biblioref"><strong>MichaelChernick?</strong></a>)</span> notes). Thus, the answer is that your second option is for non-normal repeated measures (or otherwise non-independent) data. (I should mention, in keeping with <span class="citation">(<a href="#ref-Macro" role="doc-biblioref"><strong>Macro?</strong></a>)</span>’s comment, that general-ized linear mixed models include linear models as a special case and thus can be used with normally distributed data. However, in typical usage the term connotes non-normal data.)</p>
<p>Update: (The OP has asked about GEE as well, so I will write a little about how all three relate to each other.)</p>
<p>Here’s a basic overview:</p>
<ul>
<li>a typical GLiM (I’ll use logistic regression as the prototypical case) lets you model an independent binary response as a function of covariates</li>
<li>a GLMM lets you model a non-independent (or clustered) binary response conditional on the attributes of each individual cluster as a function of covariates</li>
<li>the GEE lets you model the population mean response of non-independent binary data as a function of covariates</li>
</ul>
<p>Since you have multiple trials per participant, your data are not independent; as you correctly note, “[t]rials within one participant are likely to be more similar than as compared to the whole group.” Therefore, you should use either a GLMM or the GEE.</p>
<p>The issue, then, is how to choose whether GLMM or GEE would be more appropriate for your situation. The answer to this question depends on the subject of your research–specifically, the target of the inferences you hope to make. As I stated above, with a GLMM, the betas are telling you about the effect of a one unit change in your covariates on a particular participant, given their individual characteristics. On the other hand with the GEE, the betas are telling you about the effect of a one unit change in your covariates on the average of the responses of the entire population in question. This is a difficult distinction to grasp, especially because there is no such distinction with linear models (in which case the two are the same thing).</p>
<p>One way to try to wrap your head around this is to imagine averaging over your population on both sides of the equals sign in your model. For example, this might be a model:</p>
<p><span class="math display">\[logit(p_i)=β_0+β_1X_1+b_i\]</span></p>
<p>where:</p>
<p><span class="math inline">\(logit(p)=ln(\frac{p}{1−p})\)</span>, &amp; <span class="math inline">\(b∼N(0,σ_{b}^2)\)</span></p>
<p>There is a parameter that governs the response distribution (pp, the probability, with binary data) on the left side for each participant. On the right hand side, there are coefficients for the effect of the covariate[s] and the baseline level when the covariate[s] equals 0. The first thing to notice is that the actual intercept for any specific individual is not β0_0, but rather (β0+bi)(_0+b_i). But so what? If we are assuming that the bib_i’s (the random effect) are normally distributed with a mean of 0 (as we’ve done), certainly we can average over these without difficulty (it would just be β0_0). Moreover, in this case we don’t have a corresponding random effect for the slopes and thus their average is just β1_1. So the average of the intercepts plus the average of the slopes must be equal to the logit transformation of the average of the pip_i’s on the left, mustn’t it? Unfortunately, no. The problem is that in between those two is the logit, which is a non-linear transformation. (If the transformation were linear, they would be equivalent, which is why this problem doesn’t occur for linear models.) The following plot makes this clear:</p>
<p><img src="fig/glmm_logit_StackOverflow.png" /></p>
<p>Imagine that this plot represents the underlying data generating process for the probability that a small class of students will be able to pass a test on some subject with a given number of hours of instruction on that topic. Each of the grey curves represents the probability of passing the test with varying amounts of instruction for one of the students. The bold curve is the average over the whole class. In this case, the effect of an additional hour of teaching conditional on the student’s attributes is β1_1–the same for each student (that is, there is not a random slope). Note, though, that the students baseline ability differs amongst them–probably due to differences in things like IQ (that is, there is a random intercept). The average probability for the class as a whole, however, follows a different profile than the students. The strikingly counter-intuitive result is this: an additional hour of instruction can have a sizable effect on the probability of each student passing the test, but have relatively little effect on the probable total proportion of students who pass. This is because some students might already have had a large chance of passing while others might still have little chance.</p>
<p>The question of whether you should use a GLMM or the GEE is the question of which of these functions you want to estimate. If you wanted to know about the probability of a given student passing (if, say, you were the student, or the student’s parent), you want to use a GLMM. On the other hand, if you want to know about the effect on the population (if, for example, you were the teacher, or the principal), you would want to use the GEE.</p>
<p><a href="https://stats.stackexchange.com/questions/32419/difference-between-generalized-linear-models-generalized-linear-mixed-models">StackOverFlow</a></p>
<p>What are the best methods for checking a generalized linear mixed model (GLMM) for proper fit?
Unfortunately, it isn’t as straightforward as it is for a general linear model.
n linear models the requirements are easy to outline: linear in the parameters, normally distributed and independent residuals, and homogeneity of variance (that is, similar variance at all values of all predictors).</p>
<p>For linear models, there are well-described and well-implemented methods for checking each of these, both visual/descriptive methods and statistical tests.</p>
<p>It is not nearly as easy for GLMMs.</p>
<p><strong>Assumption: Random effects come from a normal distribution</strong></p>
<p>Let’s start with one of the more familiar elements of GLMMs, which is related to the random effects. There is an assumption that random effects—both intercepts and slopes—are normally distributed.</p>
<p>These are relatively easy to export to a data set in most statistical software (including SAS and R). Personally, I much prefer visual methods of checking for normal distributions, and typically go right to making histograms or normal probability plots (Q-Q plots) of each of the random effects.</p>
<p>If the histograms look roughly bell-shaped and symmetric, or the Q-Q plots generally fall close to a diagonal line, I usually consider this to be good enough.</p>
<p>If the random effects are not reasonably normally distributed, however, there are not simple remedies. In a general linear model outcomes can be transformed. In GLMMs they cannot.</p>
<p>Research is currently being conducted on the consequences of mis-specifying the distribution of random effects in GLMMs. (Outliers, of course, can be handled the same way as in generalized linear models—except that an entire random subject, as opposed to a single observation, may be examined.)</p>
<p><strong>Assumption: The chosen link function is appropriate</strong></p>
<p>Additional assumptions of GLMMs are more related to the generalized linear model side. One of these is the relationship of the numeric predictors to the parameter of interest, which is determined by the link function.</p>
<p>For both generalized linear models and GLMMs, it is important to understand that the most typical link functions (e.g., the logit for binomial data, the log for Poisson data) are not guaranteed to be a good representation of the relationship of the predictors with the outcomes.</p>
<p>Checking this assumption can become quite complicated as models become more crowded with fixed and random effects.</p>
<p>One relatively simple (though not perfect) way to approach this is to compare the predicted values to the actual outcomes.</p>
<p>With most GLMMs, it is best to compare averages of outcomes to predicted values. For example, with binomial models, one could take all of the values with predicted values near 0.5, 0.15, 0.25, etc., and average the actual outcomes (the 0s and 1s). You can then plot these average values against the predicted values.</p>
<p>If the general form of the model is correct, the differences between the predicted values and the averaged actual values will be small. (Of course how small depends on the number of observations and variance function).</p>
<p>No “patterns” in these differences should be obvious.</p>
<p>This is similar to the idea of the Hosmer-Lemeshow test for logistic regression models. If you suspect that the form of the link function is not correct, there are remedies. Possibilites include changing the link function, transforming numeric predictors, or (if necessary) categorizing continuous predictors.</p>
<p><strong>Assumption: Appropriate estimation of variance</strong></p>
<p>Finally, it is important to check the variability of the outcomes. This is also not as easy as it is for linear models, since the variance is not constant and is a function of the parameter being estimated.</p>
<p>Fortunately, this is one of the easier assumptions to check. One of the fit statistics your statistical software produces is a generalized chi-square that compares the magnitude of the model residuals to the theoretical variance.</p>
<p>The chi-square divided by its degrees of freedom should be approximately 1. If this statistic is too large, then the variance is “overdispersed” (larger than it should be). Alternatively, if the statistic is too small, the variance is “underdispersed.”</p>
<p>While the best way to approach this varies by distribution, there are options to adjust models for overdispersion that result in more conservative p-values.</p>
<p><a href="https://www.theanalysisfactor.com/regression-diagnostics-glmm/">TheAnalysisFactor</a></p>

</div>
<div id="logit" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Logit</h2>
<p>Possible Analysis methods:</p>
<p>Below is a list of some analysis methods you may have encountered. Some of the methods listed are quite reasonable while others have either fallen out of favor or have limitations.</p>
<ul>
<li>Logistic regression, the focus of this page</li>
<li>Probit regression. Probit analysis will produce results similar logistic regression. The choice of probit versus logit depends largely on individual preferences.</li>
<li>OLS regression. When used with a binary response variable, this model is known as a linear probability model and can be used as a way to describe conditional probabilities. However, the errors (i.e., residuals) from the linear probability model violate the homoskedasticity and normality of errors assumptions of OLS regression, resulting in invalid standard errors and hypothesis tests. For a more thorough discussion of these and other problems with the linear probability model.</li>
<li>Two-group discriminant function analysis. A multivariate method for dichotomous outcome variables.</li>
<li>Hotelling’s T2. The 0/1 outcome is turned into the grouping variable, and the former predictors are turned into outcome variables. This will produce an overall test of significance but will not give individual coefficients for each variable, and it is unclear the extent to which each “predictor” is adjusted for the impact of the other “predictors.”</li>
</ul>
<p><a href="https://stats.idre.ucla.edu/r/dae/logit-regression/">ucla</a></p>
<div id="odds-ratio" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Odd’s Ratio</h3>
<p>If you want to interpret the estimated effects as relative odds ratios,
just do <code>exp(coef(x))</code> (gives you <span class="math inline">\(e^β\)</span>,
the multiplicative change in the odds ratio for <span class="math inline">\(y=1\)</span>
if the covariate associated with <span class="math inline">\(β\)</span> increases by 1).</p>
<p>For profile likelihood intervals for this quantity, you can do</p>
<pre><code>require(MASS)
exp(cbind(coef(x), confint(x)))  </code></pre>
<p>To get the odds ratio, we need the classification cross-table
of the original dichotomous DV and
the predicted classification according to some probability threshold that needs to be chosen first.</p>
<p><a href="https://stats.stackexchange.com/questions/8661/logistic-regression-in-r-odds-ratio">StackOverFlow</a></p>

</div>
</div>
<div id="probit" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Probit</h2>
<p>A standard linear model (e.g., a simple regression model) can be thought of as having two ‘parts.’
These are called the structural component and the random component.
For example:</p>
<p><span class="math display">\[Y=β_0+β_1 X+ε\]</span></p>
<p>where</p>
<p><span class="math inline">\(ε∼N(0,σ^2)\)</span></p>
<p>The first two terms (that is, <span class="math inline">\(β_0 + β_1 X\)</span>) constitute the structural component,
and the <span class="math inline">\(ε\)</span> (which indicates a normally distributed error term) is the random component.</p>
<p>When the response variable is not normally distributed
(for example, if your response variable is binary) this approach may no longer be valid.</p>
<p>The generalized linear model (GLiM) was developed to address such cases,
and logit and probit models are special cases of GLiMs that are appropriate for binary variables
(or multi-category response variables with some adaptations to the process).</p>
<p>A GLiM has three parts, a <em>structural component</em>, a <em>link function</em>, and a <em>response distribution</em>.</p>
<p>For example:</p>
<p><span class="math display">\[g(μ)=β_0+β_1 X\]</span></p>
<p>Here <span class="math inline">\(β_0 + β_1 X\)</span> is again the structural component, <span class="math inline">\(g()\)</span> is the link function,
and <span class="math inline">\(μ\)</span> is a mean of a conditional response distribution at a given point in the covariate space.</p>
<p>The way we think about the structural component here doesn’t really differ from how we think about it
with standard linear models; in fact, that’s one of the great advantages of GLiMs.
Because for many distributions the variance is a function of the mean,
having fit a conditional mean (and given that you stipulated a response distribution),
you have automatically accounted for the analog of the random component in a linear model
(N.B.: this can be more complicated in practice).</p>
<p>The link function is the key to GLiMs:
since the distribution of the response variable is non-normal,
it’s what lets us connect the structural component to the response–
it ‘links’ them (hence the name).
It’s also the key to your question, since the logit and probit are links,
and understanding link functions will allow us to intelligently choose when to use which one.
Although there can be many link functions that can be acceptable,
often there is one that is special.
Without wanting to get too far into the weeds (this can get very technical) the predicted mean, <span class="math inline">\(μ\)</span>,
will not necessarily be mathematically the same as
the response distribution’s canonical location parameter;
the link function that does equate them is the canonical link function.
The advantage of this "is that a minimal sufficient statistic for <span class="math inline">\(β\)</span>.
The canonical link for binary response data (more specifically, the binomial distribution) is the logit.
However, there are lots of functions that can map the structural component onto the interval (0,1)(0,1),
and thus be acceptable; the probit is also popular, but there are yet
other options that are sometimes used (such as the <em>complementary log log</em>, <span class="math inline">\(ln(−ln(1−μ))\)</span>,
often called <em>cloglog</em>).
Thus, there are lots of possible link functions and
the choice of link function can be very important.
The choice should be made based on some combination of:</p>
<ol style="list-style-type: decimal">
<li>Knowledge of the response distribution,</li>
<li>Theoretical considerations, and</li>
<li>Empirical fit to the data.</li>
</ol>
<p>These considerations can be used to guide your choice of link.
To start with, if your response variable is the outcome of a Bernoulli trial (that is, 0 or 1),
your response distribution will be binomial,
and what you are actually modeling is the probability of an observation being a 1
(that is, <span class="math inline">\(π(Y=1)\)</span>.
As a result, any function that maps the real number line, <span class="math inline">\((−∞,+∞)\)</span>
to the interval <span class="math inline">\((0,1)\)</span> will work.</p>
<p>If you are thinking of your covariates as directly connected to the probability of success,
then you would typically choose logistic regression
because it is the canonical link.
However, consider the following example:
You are asked to model high_Blood_Pressure as a function of some covariates.
Blood pressure itself is normally distributed in the population.
Clinicians dichotomized it during the study
(that is, they only recorded ‘high-BP’ or ‘normal’).
In this case, probit would be preferable a-priori for theoretical reasons.
Your binary outcome depends on a hidden Gaussian variable.
Another consideration is that both logit and probit are symmetrical,
if you believe that the probability of success rises slowly from zero,
but then tapers off more quickly as it approaches one, the cloglog is called for.</p>
<p>Lastly, note that the empirical fit of the model to the data is
unlikely to be of assistance in selecting a link,
unless the shapes of the link functions in question differ substantially
(of which, the logit and probit do not).
For instance, consider the following simulation:</p>
<pre><code>set.seed(1)
probLower = vector(length=1000)

for(i in 1:1000){      
    x = rnorm(1000)
    y = rbinom(n=1000, size=1, prob=pnorm(x))

    logitModel  = glm(y~x, family=binomial(link=&quot;logit&quot;))
    probitModel = glm(y~x, family=binomial(link=&quot;probit&quot;))

    probLower[i] = deviance(probitModel)&lt;deviance(logitModel)
}

sum(probLower)/1000
[1] 0.695</code></pre>
<p>Even when we know the data were generated by a probit model, and we have 1000 data points,
the probit model only yields a better fit 70% of the time, and even then,
often by only a trivial amount.
Consider the last iteration:</p>
<pre><code>deviance(probitModel)
[1] 1025.759
deviance(logitModel)
[1] 1026.366
deviance(logitModel)-deviance(probitModel)
[1] 0.6076806</code></pre>
<p>The reason for this is simply that the logit and probit link functions
yield very similar outputs when given the same inputs.</p>
<p><img src="fig/glmm_probit_StackOverflow.png" /></p>
<p>The logit and probit functions are practically identical,
except that the logit is slightly further from the bounds when they ‘turn the corner.’
(Note that to get the logit and the probit to align optimally,
the logit’s <span class="math inline">\(β_1\)</span> must be <span class="math inline">\(≈1.7\)</span> times the corresponding slope value for the probit.
In addition, I could have shifted the cloglog over slightly
so that they would lay on top of each other more,
but I left it to the side to keep the figure more readable.
Notice that the cloglog is asymmetrical whereas the others are not;
it starts pulling away from 0 earlier, but more slowly,
and approaches close to 1 and then turns sharply.</p>
<p>A couple more things can be said about link functions.
First, considering the <em>identity function</em> <span class="math inline">\((g(η)=ηg(\eta)=\eta)\)</span>
as a link function allows us to understand the standard linear model
as a special case of the generalized linear model
(that is, the response distribution is normal, and the link is the identity function).
It’s also important to recognize that whatever transformation the link instantiates
is properly applied to the parameter governing the response distribution (that is, <span class="math inline">\(μ\)</span>),
not the actual response data.
Finally, because in practice we never have the underlying parameter to transform,
in discussions of these models,
often what is considered to be the actual link is left implicit and
the model is represented by the inverse of the link function
applied to the structural component instead.
That is:</p>
<p><span class="math display">\[μ=g^{−1}(β_0+β_1 X)\]</span></p>
<p>For instance, logistic regression is usually represented:</p>
<p><span class="math display">\[π(Y)=\frac{exp(β_0 + β_1 X)}{1+exp(β_0 + β_1 X)}\]</span></p>
<p>instead of:</p>
<p><span class="math display">\[ln(\frac{(π(Y)}{1−π(Y)}) = β_0 + β_1 X\]</span></p>
<p>For a quick and clear, but solid, overview of the generalized linear model,
see chapter 10 of Fitzmaurice, Laird, &amp; Ware (2004),
For how to fit these models in R, check out the documentation for the function ?glm in the base package.</p>
<p>(One final note added later:) I occasionally hear people say that
you shouldn’t use the probit, because it can’t be interpreted.
This is not true, although the interpretation of the betas is less intuitive.
With logistic regression, a one unit change in <span class="math inline">\(X_1\)</span> is associated with
a <span class="math inline">\(β_1\)</span> change in the log odds of ‘success’
(alternatively, an <span class="math inline">\(exp(β_1)\)</span>-fold change in the odds), all else being equal.
With a probit, this would be a change of <span class="math inline">\(β_1 z\)</span>’s.
(Think of two observations in a dataset with <span class="math inline">\(z\)</span>-scores of 1 and 2, for example.)
To convert these into predicted <em>probabilities</em>,
you can pass them through the normal CDF, or look them up on a <span class="math inline">\(z\)</span>-table.</p>
<p><a href="https://stats.stackexchange.com/questions/20523/difference-between-logit-and-probit-models/30909#30909">StackOverFlow</a></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inequality.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="power-law.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dyrehaugen/rsts/edit/master/201-testing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["rsts.pdf", "rsts.epub", "rsts.mobi"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
