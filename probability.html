<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Probability | Statistics</title>
  <meta name="description" content="2 Probability | Statistics" />
  <meta name="generator" content="bookdown 0.23 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Probability | Statistics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="dyrehaugen/rsts" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Probability | Statistics" />
  
  
  

<meta name="author" content="Dyrehaugen Web Notebook" />


<meta name="date" content="2021-11-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="fat-tails.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Statistics</a></li>
<li class="chapter" data-level="2" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>2</b> Probability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="probability.html"><a href="probability.html#intuition-for-probability"><i class="fa fa-check"></i><b>2.1</b> Intuition for Probability</a></li>
<li class="chapter" data-level="2.2" data-path="probability.html"><a href="probability.html#pandemic-risk-management"><i class="fa fa-check"></i><b>2.2</b> Pandemic Risk Management</a></li>
<li class="chapter" data-level="2.3" data-path="probability.html"><a href="probability.html#quarantine-fatigue-thins-fat-tailed-impacts"><i class="fa fa-check"></i><b>2.3</b> Quarantine fatigue thins fat-tailed impacts</a></li>
<li class="chapter" data-level="2.4" data-path="probability.html"><a href="probability.html#herd-immunity-impossible-with-new-mutants"><i class="fa fa-check"></i><b>2.4</b> Herd Immunity impossible with new Mutants</a></li>
<li class="chapter" data-level="2.5" data-path="probability.html"><a href="probability.html#danish-mask-study"><i class="fa fa-check"></i><b>2.5</b> Danish Mask Study</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fat-tails.html"><a href="fat-tails.html"><i class="fa fa-check"></i><b>3</b> Fat Tails</a>
<ul>
<li class="chapter" data-level="3.1" data-path="fat-tails.html"><a href="fat-tails.html#extremes"><i class="fa fa-check"></i><b>3.1</b> Extremes</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="fat-tails.html"><a href="fat-tails.html#catastrophe-principle"><i class="fa fa-check"></i><b>3.1.1</b> Catastrophe Principle</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="fat-tails.html"><a href="fat-tails.html#statistical-consequences-of-fat-tails"><i class="fa fa-check"></i><b>3.2</b> Statistical Consequences of Fat Tails</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="fat-tails.html"><a href="fat-tails.html#power-law-distributions"><i class="fa fa-check"></i><b>3.2.1</b> Power Law Distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="fat-tails.html"><a href="fat-tails.html#lindy-effect"><i class="fa fa-check"></i><b>3.3</b> Lindy Effect</a></li>
<li class="chapter" data-level="3.4" data-path="fat-tails.html"><a href="fat-tails.html#superspreaders"><i class="fa fa-check"></i><b>3.4</b> Superspreaders</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="vaccine.html"><a href="vaccine.html"><i class="fa fa-check"></i><b>4</b> Vaccine</a></li>
<li class="chapter" data-level="5" data-path="inequality.html"><a href="inequality.html"><i class="fa fa-check"></i><b>5</b> Inequality</a></li>
<li class="chapter" data-level="6" data-path="causation.html"><a href="causation.html"><i class="fa fa-check"></i><b>6</b> Causation</a>
<ul>
<li class="chapter" data-level="6.1" data-path="causation.html"><a href="causation.html#liang-causality"><i class="fa fa-check"></i><b>6.1</b> Liang Causality</a></li>
<li class="chapter" data-level="6.2" data-path="causation.html"><a href="causation.html#causation-in-chaotic-dynamic-systems"><i class="fa fa-check"></i><b>6.2</b> Causation in Chaotic Dynamic Systems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#connecting-to-theory"><i class="fa fa-check"></i><b>7.1</b> Connecting to Theory</a></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#glmm"><i class="fa fa-check"></i><b>7.2</b> GLMM</a></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#logit"><i class="fa fa-check"></i><b>7.3</b> Logit</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#odds-ratio"><i class="fa fa-check"></i><b>7.3.1</b> Odd’s Ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="p-test.html"><a href="p-test.html"><i class="fa fa-check"></i><b>8</b> P test</a>
<ul>
<li class="chapter" data-level="8.1" data-path="p-test.html"><a href="p-test.html#p-value-hacking"><i class="fa fa-check"></i><b>8.1</b> P-Value Hacking</a></li>
<li class="chapter" data-level="8.2" data-path="p-test.html"><a href="p-test.html#probit"><i class="fa fa-check"></i><b>8.2</b> Probit</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="spurious-correlation.html"><a href="spurious-correlation.html"><i class="fa fa-check"></i><b>9</b> Spurious Correlation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="spurious-correlation.html"><a href="spurious-correlation.html#trending-variables"><i class="fa fa-check"></i><b>9.1</b> Trending Variables</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="stationarity.html"><a href="stationarity.html"><i class="fa fa-check"></i><b>10</b> Stationarity</a>
<ul>
<li class="chapter" data-level="10.1" data-path="stationarity.html"><a href="stationarity.html#record-events"><i class="fa fa-check"></i><b>10.1</b> Record Events</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="power-laws.html"><a href="power-laws.html"><i class="fa fa-check"></i><b>11</b> Power laws</a>
<ul>
<li class="chapter" data-level="11.1" data-path="power-laws.html"><a href="power-laws.html#generative-models"><i class="fa fa-check"></i><b>11.1</b> Generative Models</a></li>
<li class="chapter" data-level="11.2" data-path="power-laws.html"><a href="power-laws.html#income-distribution-power-law"><i class="fa fa-check"></i><b>11.2</b> Income Distribution Power Law</a></li>
<li class="chapter" data-level="11.3" data-path="power-laws.html"><a href="power-laws.html#timescaling-rainfall"><i class="fa fa-check"></i><b>11.3</b> Timescaling Rainfall</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="syntetic-control.html"><a href="syntetic-control.html"><i class="fa fa-check"></i><b>12</b> Syntetic Control</a></li>
<li class="chapter" data-level="13" data-path="econometrics.html"><a href="econometrics.html"><i class="fa fa-check"></i><b>13</b> Econometrics</a></li>
<li class="part"><span><b>I Appendices</b></span></li>
<li class="appendix"><span><b>Appendices</b></span></li>
<li class="chapter" data-level="A" data-path="about.html"><a href="about.html"><i class="fa fa-check"></i><b>A</b> About</a></li>
<li class="chapter" data-level="B" data-path="links.html"><a href="links.html"><i class="fa fa-check"></i><b>B</b> Links</a></li>
<li class="chapter" data-level="C" data-path="news.html"><a href="news.html"><i class="fa fa-check"></i><b>C</b> NEWS</a></li>
<li class="divider"></li>
<li><a href="https://github.com/dyrehaugen/rsts" target="blank">On Github</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Probability</h1>
<div id="intuition-for-probability" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Intuition for Probability</h2>
<p><em>Fix</em></p>
<p>The human instinct for probability. By most accounts, this instinct is terrible. And that should strike you as odd. As a rule, evolution does not produce glaring flaws. (It slowly removes them.) So if you see flaws everywhere, it’s a good sign that you’re observing an organism in a foreign environment, a place to which it is not adapted.</p>
<p>When it comes to probability, I argue that humans now live in a foreign environment. But it is of our own creation. Our intuition, I propose, was shaped by observing probability in short samples — the information gleaned from a single human lifetime. But with the tools of mathematics, we now see probability as what happens in the infinite long run. It’s in this foreign mathematical environment that our intuition now lives.</p>
<p>Unsurprisingly, when we compare our intuition to our mathematics, we find a mismatch. But that doesn’t mean our intuition is wrong. Perhaps it is just solving a different problem — one not usually posed by mathematics. Our intuition, I hypothesize, is designed to predict probability in the short run. And on that front, it may be surprisingly accurate.</p>
<p>As a rule, evolutionary biologists don’t look for ‘bias’ in animal behavior. That’s because they assume that organisms have evolved to fit their environment. When flaws do appear, it’s usually because the organism is in a foreign place — an environment where its adaptations have become liabilities.3</p>
<p>As an example, take a deer’s tendency to freeze when struck by headlights. This suicidal flaw is visible because the deer lives in a foreign environment. Deer evolved to have excellent night vision in a world without steel death machines attached to spotlights. In this world, the transition from light to dark happened slowly, so there was no need for fast pupil reflexes. Nor was there a need to flee from bright light. The evolutionary result is that when struck by light, deer freeze until their eyes adjust. It’s a perfectly good behavior … in a world without cars. In the industrial world, it’s a fatal flaw.</p>
<p>Back to humans and our ‘flawed’ intuition for probability. I suspect that many apparent ‘biases’ in our probability intuition stem from a change in our social environment, a change in the way we view ‘chance’.</p>
<p><strong>The gambler’s fallacy</strong></p>
<p>On August 18, 1913, a group of gamblers at the Monte Carlo Casino lost their shirts. It happened at a roulette table, which had racked up a conspicuous streak of blacks. As the streak grew longer, the gamblers became convinced that red was ‘due’. And yet, with each new roll they were wrong. The streak finally ended after 26 blacks in a row. By then, nearly everyone had gone broke.</p>
<p>These poor folks fell victim to what we now call the gambler’s fallacy — the belief that if an event happens more frequently than normal during the past, it is less likely to happen in the future. It is a ‘fallacy’ because in games like roulette, each event is ‘independent’. It doesn’t matter if a roulette ball landed on black 25 times in a row. On the next toss, the probability of landing on black remains the same (18/37 on a European wheel, or 18/38 on an American wheel).</p>
<p>Many gamblers know that roulette outcomes are independent events, meaning the past cannot affect the future. And yet their intuition consistently tells them the opposite. Gamblers at the Monte Carlo Casino had an overwhelming feeling that after 25 blacks, the ball had to land on red.</p>
<p>The mathematics tell us that this intuition is wrong. So why would evolution give us such a faulty sense of probability?</p>
<p>It is in ‘games of chance’ (like roulette) that flaws in our probability intuition are most apparent. Curiously, it is in these same games where the mathematics of probability are best understood. I doubt this is a coincidence.</p>
<p>The Monte Carlo gamblers who lost their shirts misled by their instinct.
We <em>recognize</em> our flaws. We know that our instinct misguides us because we’ve developed formal tools for understanding probability. Importantly, these tools were forged in the very place where our intuition is faulty — by studying games of chance.</p>
<p>The crux of the problem. To get an accurate sense for innate probability, you need an absurdly large number of observations. And yet humans typically observe probability in short windows. This mismatch may be why our intuition appears wrong. It’s been shaped to predict probability within small samples.</p>
<p>The trouble is, this ‘long run’ is impossibly long.</p>
<p><img src="fig/innate_probability.png" /></p>
<p>If observers see a few hundred tosses of the coin, they will deduce the wrong probability of heads.
Even after a few thousand tosses, observers will be misled. In this simulation, it takes about 100,000 tosses before the ‘observed’ probability converges (with reasonable accuracy) to the ‘innate’ probability.</p>
<p>Few people observe 100,000 tosses of a real coin. And that means their experience can mislead. They may conclude that a coin is ‘biased’ when it is actually not. Nassim Nicholas Taleb calls this mistake getting <a href="https://en.wikipedia.org/wiki/Fooled_by_Randomness">‘fooled by randomness’</a>.</p>
<p>For outcomes that were frequent, we could develop an accurate intuition. We are excellent, for instance, at using facial expressions to judge emotions — obviously because such judgment is a ubiquitous part of social life. But for outcomes that were rare (things like droughts and floods), patterns would be nearly impossible to see.</p>
<p>As a social species, our most significant interactions are with things that do have a memory (i.e. other humans). So a good rule of thumb may be to project memory onto everything with which we interact.</p>
<p>It could be that our probability intuition is not actually flawed, but is instead a correct interpretation of the evidence … as we see it.</p>
<p>Remember that our intuition has no access to the god’s eye view of ‘innate’ probability. Our intuition evolved based only on what our ancestors observed. What’s important is that humans typically observe probability in short windows. (For instance, we watch a few dozen tosses of a coin.) Interestingly, over these short windows, independent random events <em>do</em> have a memory. Or so it appears.</p>
<p>In his article <a href="https://jasoncollins.blog/arent-we-smart-fellow-behavioural-scientists/">‘Aren’t we smart, fellow behavioural scientists’</a>, Jason Collins shows you how to give a coin a ‘memory’. Just toss it 3 times and watch what follows a heads. Repeat this experiment over and over, and you’ll conclude that the coin has a memory. After a heads, the coin is more likely to return a tails.</p>
<p><img src="fig/tails_after_head_by_multi_tosses.png" /></p>
<p>The data shouts at us that the coin has a ‘memory’. Yet we know this is impossible. What’s happening?
The coin’s apparent ‘memory’ is actually an artifact of our observation window of 3 tosses. As we lengthen this window, the coin’s memory disappears.</p>
<p>Here’s the take-home message. If you flip a coin a few times (and do this repeatedly), the evidence will suggest that the coin has a ‘memory’. Increase your observation window, though, and the ‘memory’ will disappear.</p>
<p>When the sample size is small, assuming the coin has a memory is a good way to make predictions.</p>
<p>So what is the evolutionary context of our probability intuition? It is random events viewed through a limited window — the length of a human life. In this context, it’s not clear that our probability intuition is actually biased.</p>
<p>Yes, we tend to project ‘memory’ onto random events that are actually independent. And yet when the sample size is small, projecting memory on these events is actually a good way to make predictions.</p>
<p><a href="https://economicsfromthetopdown.com/2021/07/09/is-human-probability-intuition-actually-biased/">Fix (2021) Is Human Probability Intuition Actually ‘Biased’?</a></p>

</div>
<div id="pandemic-risk-management" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Pandemic Risk Management</h2>
<p><em>Non-Ergodic</em></p>
<p><em>Paranoia or Nothing</em></p>
<p>Taleb and collegues have som very interesting methodological
remarks in the early stages of the COVID-19 outbreak:</p>
<blockquote>
<p>Clearly, we are dealing with an extreme fat-tailed process
owing to an increased connectivity, which increases the
spreading in a nonlinear way. Fat tailed processes
have special attributes, making conventional risk-management
approaches inadequate</p>
</blockquote>
<blockquote>
<p>The general (non-naive) precautionary principle delin-
eates conditions where actions must be taken to reduce risk
of ruin, and traditional cost-benefit analyses must not be used.
These are ruin problems where, over time, exposure to tail
events leads to a certain eventual extinction. While there
is a very high probability for humanity surviving a single
such event, over time, there is eventually zero probability of
surviving repeated exposures to such events. While repeated
risks can be taken by individuals with a limited life expectancy,
ruin exposures must never be taken at the systemic and
collective level. In technical terms, the precautionary principle
applies when traditional statistical averages are invalid because
risks are not ergodic.</p>
</blockquote>
<blockquote>
<p>Historically based estimates of spreading
rates for pandemics in general, and for the current one in
particular, underestimate the rate of spread because of the
rapid increases in transportation connectivity over recent years.
This means that expectations of the extent of harm are under-
estimates both because events are inherently fat tailed, and
because the tail is becoming fatter as connectivity increases</p>
</blockquote>
<blockquote>
<p>Estimates of the virus’s reproductive
ratio <span class="math inline">\(R\_{0}\)</span> —the number of cases one case generates on average
over the course of its infectious period in an otherwise
uninfected population—are biased downwards. This property
comes from fat-tailedness due to individual ‘superspreader’
events. Simply,<span class="math inline">\(R\_{0}\)</span> is estimated from an average which takes
longer to converge as it is itself a fat-tailed variable.</p>
</blockquote>
<p><a href="https://necsi.edu/systemic-risk-of-pandemic-via-novel-pathogens-coronavirus-%20a-note">Norman/Bar-Yam/Taleb Note</a>
<a href="/pdf/Joseph_Norman_2020_Systemic_Risk_of_Pandemic_via_Novel_Pathogenes.pdf">(pdf)</a></p>

</div>
<div id="quarantine-fatigue-thins-fat-tailed-impacts" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Quarantine fatigue thins fat-tailed impacts</h2>
<p><em>Abstract Conte:</em></p>
<p>Fat-tailed damages across disease outbreaks limit the
ability to learn and prepare for future outbreaks,
as the central limit theorem slows down and fails
to hold with infinite moments.</p>
<p>We demonstrate the emergence and persistence of fat tails in contacts across the U.S.
We then demonstrate an interaction between these contact rate distributions
and community-specific disease dynamics
to create fat-tailed distributions of COVID-19 impacts
(proxied by weekly cumulative cases and deaths) during the
exact time when attempts at suppression were most intense.</p>
<p>Our stochastic SIR model implies the effective reproductive number
also follows a fat-tailed stochastic process and leads to multiple waves of
cases with unpredictable timing and magnitude instead of a single noisy wave of cases
found in many compartmental models
that introduce stochasticity via an additively-separable error term.</p>
<p>Public health policies developed based on experiences during these months
could be viewed as an overreaction if these impacts were
mistakenly perceived as thin tailed,
possibly contributing to reduced compliance, regulation, and the quarantine fatigue.</p>
<p>While fat-tailed contact rates associated with superspreaders increase transmission
and case numbers, they also suggest a potential benefit: targeted policy
interventions are more effective than they would be with thin-tailed contacts.</p>
<p>If policy makers have access to the necessary information and a mandate to act decisively,
they might take advantage of fat-tailed contacts
to prevent inaction that normalizes case and death counts that
would seem extreme early in the outbreak.</p>
<p>Our place-based estimates of contacts aid in these efforts by showing
the dynamic nature of movement through communities as the outbreak progresses,
which is quite costly to achieve in network models,
forcing the assumption of static contact networks in many models.</p>
<p>In extreme value theory, fat tails confound efforts to prepare for future extreme events
like natural disasters and violent conflicts because
experience does not provide reliable information about future tail draws.
However, impacts of extreme events play out over time based on policy and
behavioral responses to the event,
which are themselves dynamically informed by past experiences.</p>
<p>A general pattern of fat-tailed contact rate distributions across the U.S.
suggests that fat tails in U.S. cases observed early in the outbreak
are due to city- and county-specific contact networks and epidemiological dynamics.</p>
<p>By unpacking the dynamics that lead to the impacts of extreme events, we show that
1) fat-tailed impacts can also confound efforts to control and manage impacts
in the midst of extreme events and
2) thin tails in disease impacts are not necessarily desirable,
if they indicate an inevitable catastrophe.</p>
<p><a href="https://www.medrxiv.org/content/10.1101/2021.01.07.21249366v1">Conte (2021) Quarantine fatigue thins fat-tailed coronavirus impacts</a>
<a href="pdf/Conte_2021_Fat-tailed_Corona.pdf">(pdf)</a>
<a href="pdf/Conte_2021_Fat-tailed_Corona_SM.pdf">(pdf - SM)</a></p>
</div>
<div id="herd-immunity-impossible-with-new-mutants" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Herd Immunity impossible with new Mutants</h2>
<p>Professor of vaccinology Shabir Madhi at the University of the Witwatersrand says protecting at-risk individuals against severe Covid is more important than herd immunity</p>
<p>Leading vaccine scientists are calling for a rethink of the goals of vaccination programmes, saying that herd immunity through vaccination is unlikely to be possible because of the emergence of variants like that in South Africa.</p>
<p>The comments came as the University of Oxford and AstraZeneca acknowledged that their vaccine will not protect people against mild to moderate Covid illness caused by the South African variant.</p>
<p>Novavax and Janssen, which were trialled there in recent months and were found to have much reduced protection against the variant – at about 60%. Pfizer/BioNTech and Moderna have also said the variant affects the efficacy of their vaccines, although on the basis of lab studies only.</p>
<p>These findings recalibrate thinking about how to approach the pandemic virus and shift the focus from the goal of herd immunity against transmission to the protection of all at-risk individuals in the population against severe disease.</p>
<p>We probably need to switch to protecting the vulnerable, with the best vaccines we have which, although they don’t stop infection, they probably do stop you dying.</p>
<p><a href="https://www.theguardian.com/society/2021/feb/07/scientists-call-for-rethink-as-doubts-grow-about-achieving-herd-immunity">Vaccine vs New Mutants (Guardian)</a></p>

</div>
<div id="danish-mask-study" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Danish Mask Study</h2>
<p>Every study needs its own statistical tools, adapted to the specific problem, which is why it is a good practice to require that statisticians come from mathematical probability rather than some software-cookbook school. When one uses canned software statistics adapted to regular medicine (say, cardiology), one is bound to make severe mistakes when it comes to epidemiological problems in the tails or ones where there is a measurement error. The authors of the study discussed below (The Danish Mask Study) both missed the effect of false positive noise on sample size and a central statistical signal from a divergence in PCR results.
<strong>A correct computation of the odds ratio shows a massive risk reduction coming from masks.</strong></p>
<p>The article by Bundgaard et al., [“Effectiveness of Adding a Mask Recommendation to Other Public Health Measures to Prevent SARS-CoV-2 Infection in Danish Mask Wearers”, Annals of Internal Medicine (henceforth the “Danish Mask Study”)] relies on the standard methods of randomized control trials to establish the difference between the rate of infections of people wearing masks outside the house v.s. those who don’t (the control group), everything else maintained constant.
The authors claimed that they calibrated their sample size to compute a p-value (alas) off a base rate of 2% infection in the general population.
The result is a small difference in the rate of infection in favor of masks (2.1% vs 1.8%, or 42/2392 vs. 53/2470), deemed by the authors as not sufficient to warrant a conclusion about the effectiveness of masks.</p>
<p><img src="fig/Bundgaard_Study_Flow.jpg" /></p>
<p>…</p>
<p><img src="fig/Bundgaard_Outcome_Components.jpg" /></p>
<p><em>Taleb’s Points:</em></p>
<blockquote>
<p>The Mask Group has 0/2392 PCR infections vs 5/2470 for the Control Group. Note that this is the only robust result and the authors did not test to see how nonrandom that can be. They missed on the strongest statistical signal. (One may also see 5 infections vs. 15 if, in addition, one accounts for clinically detected infections.)</p>
</blockquote>
<blockquote>
<p>The rest, 42/2392 vs. 53/2470, are from antibody tests with a high error rate
which need to be incorporated via propagation of uncertainty-style methods
on the statistical significance of the results.
Intuitively a false positive rate with an expected “true value” <span class="math inline">\(p\)</span>
is a random variable <span class="math inline">\(\rightarrow\)</span> Binomial Distribution with STD <span class="math inline">\(\sqrt{n p (1-p)}\)</span></p>
</blockquote>
<blockquote>
<p>False positives must be deducted in the computation of the odds ratio.</p>
</blockquote>
<blockquote>
<p><strong>The central problem is that both p and the incidence of infection are in the tails!</strong></p>
</blockquote>
<blockquote>
<p>As most infections happen at home, the study does not inform on masks in general –it uses wrong denominators for the computation of odds ratios (mixes conditional and unconditional risk). Worse, the study is not even applicable to derive information on masks vs. no masks outside the house since during most of the study (April 3 to May 20, 2020), “cafés and restaurants were closed “, conditions too specific and during which the infection rates are severely reduced –tells us nothing about changes in indoor activity. (The study ended June 2, 2020). A study is supposed to isolate a source of risk; such source must be general to periods outside the study (unlike cardiology with unconditional effects).</p>
</blockquote>
<blockquote>
<p>The study does not take into account the fact that masks might protect others. Clearly this is not cardiology but an interactive system.</p>
</blockquote>
<blockquote>
<p>Statistical signals compound. One needs to input the entire shebang, not simple individual tests to assess the joint probability of an effect.</p>
</blockquote>
<p><em>Comment from Tom Wenseleers</em>
For the 5 vs 0 PCR positive result the p value you calculate is flawed. The correct way to do it would e.g. be using a Firth logistic regression. Using R that would give you:</p>
<pre><code>library(brglm)
summary(brglm(cbind(pcrpos, pcrneg) ~ treatment, family=binomial, data=data.frame(treatment=factor(c(“masks”,”nomasks”)),
pcrpos=c(0,5), pcrneg=c(2392,2470-5))))

2-sided p=0.11.
So that’s not significantly different.

Alternatively, you might use a Fisher’s exact test, which would give you :

fisher.test(cbind(c(0,2392),c(5,2470-5))):

2-sided p = 0.06.
Again, not significantly different.</code></pre>
<p>A Firth logistic regression would be more appropriate though, since we have a clear outcome variable here and we don’t just want to test for an association in a 2×2 contingency table, as one would do using a Fisher’s exact test. For details see Firth, D. (1993). Bias reduction of maximum likelihood estimates. Biometrika 80, 27–38. A regular logistic regression doesn’t work here btw because of complete separation, <a href="https://en.wikipedia.org/wiki/Separation_(statistics)" class="uri">https://en.wikipedia.org/wiki/Separation_(statistics)</a> <a href="https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression" class="uri">https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression</a>. Going Bayesian would also be a solution, e.g. using the bayesglm() or brms package, or one could use an L1 or L2 norm or elastic net penalized binomial GLM model, e.g. using glmnet.</p>
<p>But the p value you calculate above is definitely not correct. Sometimes it helps to not try to reinvent the wheel.</p>
<p>The derivation of Fisher’s exact test you can find in most Statistics 101 courses, see e.g. <a href="https://mathworld.wolfram.com/FishersExactTest.html" class="uri">https://mathworld.wolfram.com/FishersExactTest.html</a>. For Firth’s penalized logistic regression, see <a href="https://medium.com/datadriveninvestor/firths-logistic-regression-classification-with-datasets-that-are-small-imbalanced-or-separated-49d7782a13f1" class="uri">https://medium.com/datadriveninvestor/firths-logistic-regression-classification-with-datasets-that-are-small-imbalanced-or-separated-49d7782a13f1</a> for a derivation. Or in Firth’s original article: <a href="https://www.jstor.org/stable/2336755?seq=1#metadata_info_tab_contents" class="uri">https://www.jstor.org/stable/2336755?seq=1#metadata_info_tab_contents</a>.</p>
<p>Technically, the problem with the way you calculated your p value above is that you use a one-sample binomial test, and assume there is no sampling uncertainty on the p=5/2470. Which is obviously not correct. So you need a two-sample binomial test instead, which you could get via a logistic regression. But since you have complete separation you then can’t use a standard binomial GLM, and have to use e.g. a Firth penalized logistic regression instead. Anyway, the details are in the links above.</p>
<p>You write “The probability of having 0 realizations in 2392
if the mean is <span class="math inline">\(\frac{5}{2470}\)</span> is 0.0078518, that is 1 in 127.
We can reexpress it in p values, which would be &lt;.01”.
This statement is obviously not correct then.</p>
<p>And if you didn’t do p values – well, then your piece above is a little weak as a reply on how the authors should have done their hypothesis testing in a proper way, don’t you think? If the 0 vs 5 PCR positive result is not statistically significant I don’t see how you can make a sweeping statement like “The Mask Group has 0/2392 PCR infections vs 5/2470 for the Control Group. Note that this is the only robust result and the authors did not test to see how nonrandom that can be. They missed on the strongest statistical signal.”. That “strong statistical signal” you mention turns out not be statistically significant at the p&lt;0.05 level if you do your stats properly…</p>
<p>Taleb:You are conflating p values and statistical significance.
Besides, I don’t do P values. <a href="https://arxiv.org/pdf/1603.07532.pdf" class="uri">https://arxiv.org/pdf/1603.07532.pdf</a></p>
<p>you can also work with Bayes Factors if you like. Anything more formal than what you have above should do really… But just working with a PMF of a binomial distribution, and ignoring the sampling error on the 5/2470 control group is not OK. And if you’re worried about the accuracy of p values you could always still calculate 95% confidence limits on them, right? Also not really what people would typically consider p-hacking…</p>
<p>Your title may a bit of a misnomer then. And as I mentioned: if one is worried about the accuracy of your p values &amp; stochasticity on its estimated value, you can always calculate p-value prediction intervals, <a href="https://royalsocietypublishing.org/doi/10.1098/rsbl.2019.0174" class="uri">https://royalsocietypublishing.org/doi/10.1098/rsbl.2019.0174</a>.</p>
<p>You are still ignoring the sampling uncertainty on the 0/2392. If you would like to go Monte Carlo you can use an exact-like logistic regression (<a href="https://www.jstatsoft.org/article/view/v021i03/v21i03.pdf" class="uri">https://www.jstatsoft.org/article/view/v021i03/v21i03.pdf</a>). Using R, that gives me</p>
<p>For the 0 vs 5 PCR positive result:</p>
<pre><code>library(elrm)
set.seed(1)
fit = elrm(pcrpos/n ~ treatment, ~ treatment,
r=2, iter=400000, burnIn=1000,
dataset=data.frame(treatment=factor(c(“masks”, “control”)), pcrpos=c(0, 5), n=c(2392, 2470)) )
fit$p.values # p value = 0.06, ie just about not significant at the 0.05 level
fit$p.values.se # standard error on p value = 0.0003 # this is very close to the 2-sided Fisher exact test p value
fisher.test(cbind(c(0,2392), c(5,2470-5))) # p value = 0.06

For the 0 vs 15 result:
set.seed(1)
fit = elrm(pcrpos/n ~ treatment, ~ treatment,
r=2, iter=400000, burnIn=1000,
dataset=data.frame(treatment=factor(c(“masks”, “control”)), pos=c(5, 15), n=c(2392, 2470)) )
fit$p.values # p value = 0.04 – this would be just about significant at the 0.05 level
fit$p.values.se # standard error on p value = 0.0003</code></pre>
<p>So some evidence for the opposite conclusions as what they have (especially for the 5 vs 15 result), but still not terribly strong.</p>
<p>Details of method are in <a href="https://www.jstatsoft.org/article/view/v021i03/v21i03.pdf" class="uri">https://www.jstatsoft.org/article/view/v021i03/v21i03.pdf</a>.</p>
<p>I can see you don’t like canned statistics. And you could recode these kinds of methods quite easily in Mathematica if you like, see here for a Fisher’s exact test e.g.:
<a href="https://mathematica.stackexchange.com/questions/41450/better-way-to-get-fisher-exact" class="uri">https://mathematica.stackexchange.com/questions/41450/better-way-to-get-fisher-exact</a>.</p>
<p>But believe me – also Sir Ronald Fisher will have thought long and hard about these kinds of problems. And he would have seen in seconds that what you do above is simply not correct. Quite big consensus on that if I read the various comments here by different people…</p>
<p>I was testing the hypothesis of there being no difference in infection rate between both groups and so was doing 2-sided tests. Some have argued that masks could actually make things worse if not used properly. So not doing a directional test would seem most objective to me. But if you insist, then yes, you could use 1-tailed p values… Then you would get 1-sided p values of 0.03 and 0.02 for the 0 vs 5 and 5 vs 15 sections of the data. Still deviates quite a bit from the p&lt;0.01 that you first had.</p>
<p>In terms of double column joint distribution: then I think your code above should have e.g. 15/2470 and 5/2392 as your expectation of the Bernoulli distribution for vs 5 vs 15 comparison. But that would give problems for the 0/2392 outcome for the masks group in the 0 vs 5 comparison. As simulated Bernouilli trials with p=0 will be all zeros. Also, right now I don’t see where that 2400 was coming from in your code. I get that you are doing a one-sided two-sample binomial test here via a MC approach. That’s not the same than a Fisher exact test though.</p>
<p><em>Andreas:</em>
Weird, the last part of my comment above apparently got chopped up somehow. Ignore the CI calculations as they got messed up, but are trivial. Trying again with the text that got lost, containing my main point:</p>
<p>So the false positive-adjusted Odds Ratio is .71 [95% CI .41, 1.21], using the same model as the authors of the paper did. This can be compared to their reported OR = .82 [95% CI .54, 1.23].</p>
<p>Even with my quite conservative adjustment, the only robust finding claimed in the paper is not robust anymore – the estimated risk reduction is no longer significantly lower than 50%, according to the same standard logistic model used by the authors. Nor is it sig. larger than 0%. The CI did not really improve over the unadjusted one (maybe this was obvious a priori, but not to me). Either way I think .71 is a better estimate than the .82 that was reported in the paper, based on Nassim’s reasoning about the expected false positives. And .71 vs. .82 might well have crossed the line for a mask policy to be seriously considered, by some policymaker who rejected .82 as too close to 1.</p>
<p>Sensitivity analysis of the FPR adjustment:
1% FPR (Nassim’s suggestion from the blog post) =&gt; OR = .66 [95% CI .36, 1.19]
.5% FPR (lower estimate from the Bundgaard et al. paper, based on a previous study) =&gt; OR = .76 [95% CI .47, 1.22]</p>
<p><em>Tom</em></p>
<p>I do agree with all the shortcomings of this study in general though. It certainly was massively underpowered.</p>
<p><em>Other comments:</em></p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/33205991/">Bundgaard (2020) Effectiveness of Adding Mask</a>
<a href="https://www.acpjournals.org/doi/10.7326/M20-6817">Same in Annals</a></p>
<p><a href="pdf/Bundgaard_2020_Mask_Effectiveness_ref_Taleb.pdf">(pdf)</a></p>
<p><a href="https://fooledbyrandomnessdotcom.wordpress.com/2020/11/25/hypothesis-testing-in-the-presence-of-false-positives-the-flaws-in-the-danish-mask-study/">Taleb Review of Bundgaard</a></p>
<p><a href="https://medium.com/incerto/the-masks-masquerade-7de897b517b7">Taleb Medium</a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2938757/">Odd’s Ratio Explained (NIH)</a></p>
<p><em>Composite Endpoints:</em></p>
<p>Composite endpoints in clinical trials are composed of primary endpoints that contain two or more distinct component endpoints. The purported benefits include increased statistical efficiency, decrease in sample-size requirements, shorter trial duration, and decreased cost. However, the purported benefits must be diligently weighed against the inherent challenges in interpretation. Furthermore, the larger the gradient in importance, frequency, or results between the component endpoints, the less informative the composite endpoint becomes, thereby decreasing its utility for medical-decision making.</p>
<p>[Composite Endpoints (NIH)] (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6040910/" class="uri">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6040910/</a>)</p>
<p><a href="https://en.wikipedia.org/wiki/Separation_(statistics)">Separation (Wikipedia)</a></p>
<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5654877/">Intention to treat vs Per Protocol</a></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="fat-tails.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/dyrehaugen/rsts/edit/master/100-probability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["rsts.pdf", "rsts.epub", "rsts.mobi"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
